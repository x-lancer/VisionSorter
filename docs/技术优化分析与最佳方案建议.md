# 珠子视觉分选系统 - 技术优化分析与最佳方案建议

**文档日期**: 2026年1月13日  
**版本**: v2.0  
**文档性质**: 技术深度分析与方案重构建议

---

## 执行摘要 (Executive Summary)

通过对现有可行性分析报告、代码实现以及EI400H分选卡硬件的综合分析，本文档提出了一套**可推倒重来**的技术优化方案。核心结论：

1. **当前实现与设计方案存在巨大差距** - MVP代码使用HSV硬编码阈值，完全不符合"动态发现"的业务需求
2. **硬件集成缺失** - EI400H分选卡未在代码中体现，软硬件协同方案不完整
3. **存在架构性改进空间** - 从单线程串行处理升级为多级流水线+异步处理架构

---

## 一、现状问题诊断 (Problem Diagnosis)

### 1.1 代码实现与设计方案的背离

#### 问题1: 颜色空间选择错误
- **报告要求**: 使用 **CIELAB 颜色空间** + ΔE距离度量
- **实际代码** (`bead_classifier_mvp.py`): 使用 **HSV颜色空间** + 硬编码阈值
- **影响**: 
  - HSV的Hue值对光照变化敏感，不适合工业级颜色识别
  - 硬编码阈值（如`35 <= mean_h <= 85`判断绿色）无法应对未知颜色类别
  - **完全背离"动态自适应发现"的核心需求**

#### 问题2: 聚类算法未实现
- **报告要求**: Static Leader Algorithm (首样基准增量聚类)
- **实际代码**: 无聚类逻辑，只有简单的if-else硬分类
- **影响**: 系统不具备自动发现新颜色的能力

#### 问题3: 白平衡校准缺失
- **报告要求**: 必须进行标准白卡校准，计算RGB增益系数
- **实际代码**: 无白平衡相关代码
- **影响**: 颜色测量精度无法保证，环境光变化会导致误判

### 1.2 硬件集成方案不完整

#### EI400H分选卡集成缺失
根据PDF文件名`EI400H高速分选卡编程手册V2.4.pdf`，该硬件应为分选执行机构，但：
- 代码中未找到EI400H的通信接口实现
- 可行性报告中仅提到"Modbus TCP / Socket"或"IO板卡"等通用方案，未具体对接EI400H
- **风险**: 视觉识别完成后无法可靠触发分选动作

**需要借鉴EI400H手册的内容**:
- 分选卡的具体通信协议（可能是PCIe、PCI、或自定义接口）
- 触发时序要求（脉冲宽度、延迟参数）
- 多通道控制能力（报告提到MAX_PORTS限制）
- 高速同步机制（避免时序误差导致误分选）

---

## 二、技术优化方向 (Technical Optimization Directions)

### 2.1 算法层面优化

#### 优化1: 颜色空间与距离度量 ⭐⭐⭐⭐⭐
**当前问题**: HSV不适合工业应用
**优化方案**: 
```python
# 推荐方案：CIELAB + ΔE2000（而非简单的欧氏距离）
from colormath.color_objects import LabColor, sRGBColor
from colormath.color_conversions import convert_color
from colormath.color_diff import delta_e_cie2000

# 优势：
# 1. ΔE2000是最接近人眼感知的颜色差异度量（比ΔE76精确3-5倍）
# 2. LAB空间对光照变化相对稳定
# 3. 符合国际色彩科学标准（ISO/CIE标准）
```

**备选优化**: 如果CPU算力紧张，可采用**ΔE94**（计算量约为ΔE2000的1/3，精度仍优于HSV）

#### 优化2: 自适应阈值策略 ⭐⭐⭐⭐⭐
**当前问题**: 单一固定阈值无法应对不同颜色类别
**优化方案**: 
- **分级阈值策略**:
  - 浅色珠子（L>70）: 阈值=8（人眼对浅色差异更敏感）
  - 深色珠子（L<30）: 阈值=12（深色允许更大容差）
  - 中间色调: 阈值=10
- **动态阈值学习**（可选）:
  - 记录每个类别的历史ΔE分布
  - 使用3σ原则自适应调整阈值（`threshold = mean(ΔE_history) + 3*std(ΔE_history)`）

#### 优化3: 特征提取优化 ⭐⭐⭐⭐
**报告已有**: 中心加权采样（圆心40%区域）
**可进一步优化**:
```python
# 1. 多区域采样策略（借鉴珠宝分级仪）
def extract_multi_zone_lab(image, mask):
    """
    提取珠子中心、边缘、过渡区的LAB值，加权融合
    - 中心区(30%): 权重0.6 (最纯净)
    - 过渡区(30-60%): 权重0.3
    - 边缘区(60-100%): 权重0.1 (受背景干扰大)
    """
    # 实现多区域mask生成与加权平均
    pass

# 2. 中值滤波替代均值（抗高光干扰更强）
lab_median = np.median(lab_pixels, axis=0)  # 而非 mean
```

#### 优化4: 拒识与异常检测增强 ⭐⭐⭐⭐
**报告提到**: 面积过大归入异常口
**可扩展的拒识规则**:
- **形状异常**: 长宽比 > 2.0 (可能是连珠)
- **高光面积**: 亮度>240的像素占比 > 30% (可能是反光过强)
- **边缘不清晰**: 轮廓梯度标准差 < 阈值 (可能是对焦不准)
- **颜色奇异值**: LAB值超出合理范围（L<0或>100, a/b超出±128）

---

### 2.2 架构层面优化（可推倒重来）

#### 架构问题诊断
**当前架构**: 单线程串行处理（拍照→处理→分类→输出）
**瓶颈**:
1. 相机等待算法处理完成才能拍下一张（吞吐量受限于最慢环节）
2. 无法充分利用多核CPU
3. 硬触发到分选动作的延迟不可控

#### 优化架构: 多级流水线 + 异步处理 ⭐⭐⭐⭐⭐

```
┌─────────────┐     ┌──────────────┐     ┌─────────────┐     ┌─────────────┐
│  相机采集层  │ --> │  图像预处理层 │ --> │  特征提取层  │ --> │  分类决策层  │
│ (异步线程1) │     │ (异步线程2)  │     │ (异步线程3)  │     │ (异步线程4)  │
└─────────────┘     └──────────────┘     └─────────────┘     └─────────────┘
      ↓                    ↓                    ↓                    ↓
┌─────────────────────────────────────────────────────────────────────────┐
│                        消息队列 (Queue)                                  │
│  - 每层之间使用线程安全的Queue传递数据                                   │
│  - 支持背压控制（Backpressure）防止内存溢出                              │
└─────────────────────────────────────────────────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────┐
│                      EI400H分选卡控制层 (主线程)                         │
│  - 接收分类结果                                                        │
│  - 根据传送带编码器位置计算延迟                                          │
│  - 精确触发分选动作（微秒级精度）                                        │
└─────────────────────────────────────────────────────────────────────────┘
```

**实现框架**:
```python
import queue
import threading
from collections import deque
import time

class PipelineStage:
    """流水线阶段基类"""
    def __init__(self, input_queue, output_queue, max_queue_size=10):
        self.input_queue = input_queue
        self.output_queue = output_queue
        self.thread = None
        self.running = False
        
    def process(self, data):
        raise NotImplementedError
        
    def run(self):
        while self.running:
            try:
                data = self.input_queue.get(timeout=0.1)
                result = self.process(data)
                if result:
                    self.output_queue.put(result)
            except queue.Empty:
                continue
                
    def start(self):
        self.running = True
        self.thread = threading.Thread(target=self.run)
        self.thread.start()

class VisionPipeline:
    """多级视觉处理流水线"""
    def __init__(self):
        # 创建队列链
        self.capture_queue = queue.Queue(maxsize=5)
        self.preprocess_queue = queue.Queue(maxsize=5)
        self.feature_queue = queue.Queue(maxsize=5)
        self.classify_queue = queue.Queue(maxsize=5)
        
        # 创建处理阶段
        self.preprocessor = PreprocessStage(self.capture_queue, self.preprocess_queue)
        self.feature_extractor = FeatureExtractStage(self.preprocess_queue, self.feature_queue)
        self.classifier = ClassifyStage(self.feature_queue, self.classify_queue)
        
    def start(self):
        self.preprocessor.start()
        self.feature_extractor.start()
        self.classifier.start()
        
    def feed_image(self, image, timestamp, position):
        """相机回调函数调用此方法"""
        self.capture_queue.put({
            'image': image,
            'timestamp': timestamp,
            'position': position  # 编码器位置（用于延迟补偿）
        }, block=False)
```

**性能提升预期**:
- 吞吐量: 单线程20ms/张 → 流水线5-8ms/张（理论提升2.5-4倍）
- 延迟: 端到端延迟从40ms降至25ms（各阶段并行执行）

---

### 2.3 硬件集成优化

#### EI400H分选卡集成方案（需参考PDF手册）

**假设的集成方案**（需根据实际PDF内容调整）:

1. **通信接口**
   ```python
   # 方案A: PCIe接口（如果EI400H是PCIe卡）
   import pcie_interface  # 需要厂商提供的驱动封装
   
   # 方案B: 串口/USB（如果EI400H通过串口通信）
   import serial
   ser = serial.Serial('COM3', 115200, timeout=0.1)
   
   # 方案C: 以太网（如果EI400H支持网络通信）
   import socket
   sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
   sock.connect(('192.168.1.100', 502))  # Modbus TCP
   ```

2. **时序控制关键点**
   ```python
   class SorterController:
       def __init__(self, conveyor_speed_mm_per_ms=100):
           self.conveyor_speed = conveyor_speed_mm_per_ms
           self.sorter_delay_ms = 50  # 从拍照位置到分选位置的物理延迟
           self.pulse_width_ms = 10   # 分选动作脉冲宽度（需查手册）
           
       def trigger_sort(self, category_id, capture_position, capture_time):
           """
           计算精确触发时间
           - capture_position: 编码器位置（mm）
           - sorter_position: 分选机构位置（mm）
           - delay = (sorter_position - capture_position) / speed
           """
           sorter_position = 500  # 分选位置（需现场测量）
           distance_to_sorter = sorter_position - capture_position
           delay_ms = distance_to_sorter / self.conveyor_speed
           
           # 启动定时器，精确触发
           threading.Timer(delay_ms / 1000.0, 
                          lambda: self._fire_channel(category_id)).start()
           
       def _fire_channel(self, channel_id):
           # 发送分选命令到EI400H
           # 格式需参考编程手册
           pass
   ```

3. **多通道管理**
   ```python
   class MultiChannelSorter:
       """管理多个分选通道（对应不同颜色类别）"""
       def __init__(self, max_channels=8):
           self.channels = [False] * max_channels  # 通道占用状态
           self.category_to_channel = {}  # 类别ID -> 通道ID映射
           
       def assign_channel(self, category_id):
           """为新类别分配通道"""
           if category_id in self.category_to_channel:
               return self.category_to_channel[category_id]
               
           for ch_id in range(len(self.channels)):
               if not self.channels[ch_id]:
                   self.channels[ch_id] = True
                   self.category_to_channel[category_id] = ch_id
                   return ch_id
           return None  # 通道已满
   ```

---

### 2.4 工程实践优化

#### 优化1: 状态持久化 ⭐⭐⭐⭐
**问题**: 系统重启后，已学习的颜色类别丢失
**方案**: 
```python
import json
import pickle
from pathlib import Path

class ClusterDatabase:
    """持久化存储类别基准向量"""
    def __init__(self, db_path='clusters.json'):
        self.db_path = Path(db_path)
        self.clusters = {}  # {category_id: {'lab_vector': [...], 'sample_count': int, 'first_sample_image': str}}
        
    def load(self):
        if self.db_path.exists():
            with open(self.db_path, 'r') as f:
                data = json.load(f)
                self.clusters = data
        return self
        
    def save(self):
        with open(self.db_path, 'w') as f:
            json.dump(self.clusters, f, indent=2)
            
    def add_cluster(self, category_id, lab_vector, sample_image):
        self.clusters[category_id] = {
            'lab_vector': lab_vector.tolist(),
            'sample_count': 1,
            'first_sample_image': sample_image,  # 保存首样图片路径
            'created_time': time.time()
        }
        self.save()
```

#### 优化2: 可视化调试界面 ⭐⭐⭐
**问题**: 算法黑盒，无法直观了解分类过程
**方案**: 使用OpenCV或PyQt创建实时监控界面
```python
class VisualizationPanel:
    """实时显示分类结果、基准对比、统计信息"""
    def __init__(self):
        self.window_name = "Vision Sorter Monitor"
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        
    def update(self, image, classification_result, cluster_db):
        # 在原图上标注: 类别ID、ΔE值、置信度
        annotated = image.copy()
        cv2.putText(annotated, f"Class: {classification_result['category_id']}", 
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)
        cv2.putText(annotated, f"ΔE: {classification_result['delta_e']:.2f}", 
                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)
        
        # 显示各类别统计柱状图
        # ...
        
        cv2.imshow(self.window_name, annotated)
        cv2.waitKey(1)
```

#### 优化3: 性能监控与日志 ⭐⭐⭐
```python
import logging
import time
from contextlib import contextmanager

class PerformanceMonitor:
    def __init__(self):
        self.stage_timings = {
            'capture': [],
            'preprocess': [],
            'feature_extract': [],
            'classify': [],
            'total': []
        }
        
    @contextmanager
    def time_stage(self, stage_name):
        start = time.perf_counter()
        yield
        elapsed = (time.perf_counter() - start) * 1000  # ms
        self.stage_timings[stage_name].append(elapsed)
        
        # 记录超时警告
        if elapsed > 20:  # 超过20ms
            logging.warning(f"{stage_name} took {elapsed:.2f}ms (exceeds 20ms threshold)")
            
    def get_statistics(self):
        stats = {}
        for stage, timings in self.stage_timings.items():
            if timings:
                stats[stage] = {
                    'mean': np.mean(timings),
                    'max': np.max(timings),
                    'p95': np.percentile(timings, 95)
                }
        return stats
```

---

## 三、可借鉴的工业实践 (Industry Best Practices)

### 3.1 色选机行业的成熟方案

| 技术点 | 工业色选机做法 | 可借鉴之处 |
|--------|---------------|-----------|
| **背景设计** | 使用**旋转背景盘**，交替黑白背景，提高对比度 | 可考虑双背景切换（但成本较高，优先考虑固定深色背景） |
| **多光谱成像** | 使用近红外(NIR)相机辅助可见光相机，区分颜色相近但材质不同的物料 | 如果后期需要区分"纹理/材质"而不仅仅是颜色，可考虑升级 |
| **FPGA预处理** | 在相机端或采集卡上进行初步图像处理（降噪、ROI裁剪） | 如果CPU成为瓶颈，可考虑USB3/GigE相机的硬件ROI功能，减少数据传输量 |
| **双相机验证** | 重要物料使用两个相机从不同角度拍摄，交叉验证 | 如果误分成本极高，可考虑此方案（但会增加延迟） |

### 3.2 机器学习领域的增量学习

| 算法 | 特点 | 适用性 |
|------|------|--------|
| **Leader Algorithm (当前方案)** | 简单、快速、无参数 | ✅ **最适合** - 符合业务需求 |
| **K-Means增量变种** | 需要指定K值，不适合未知类别数 | ❌ 不适用 |
| **DBSCAN** | 可发现任意形状聚类，但需要存储所有样本点 | ⚠️ 内存占用大，实时性差 |
| **在线K-Means** | 需要学习率参数，可能漂移 | ⚠️ 可能偏离首样基准，不符合需求 |

**结论**: Static Leader Algorithm仍是最佳选择，但可加入**置信度评估**机制:
```python
def classify_with_confidence(self, lab_vector):
    """返回分类结果 + 置信度分数"""
    min_dist, best_id = self.find_nearest_cluster(lab_vector)
    threshold = self.get_adaptive_threshold(best_id)
    
    confidence = 1.0 - (min_dist / threshold)  # 归一化到0-1
    confidence = max(0.0, min(1.0, confidence))
    
    return {
        'category_id': best_id if min_dist < threshold else None,
        'delta_e': min_dist,
        'confidence': confidence,
        'is_new_class': min_dist >= threshold
    }
```

---

## 四、推倒重来的最佳架构方案 (Optimal Architecture)

### 4.1 整体架构设计

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                             系统初始化层                                      │
│  - 加载持久化的类别数据库                                                     │
│  - 白卡校准（每次启动必做）                                                   │
│  - EI400H分选卡初始化与自检                                                   │
└─────────────────────────────────────────────────────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│                        多级异步处理流水线                                      │
│                                                                              │
│  [相机采集] → [预处理] → [特征提取] → [分类决策] → [分选控制]                │
│     ↓            ↓            ↓            ↓            ↓                    │
│   队列1        队列2        队列3        队列4        队列5                  │
│  (5帧缓冲)   (5帧缓冲)   (5帧缓冲)   (5帧缓冲)   (实时)                     │
└─────────────────────────────────────────────────────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│                          监控与诊断层                                         │
│  - 实时可视化界面（可选，生产环境可关闭）                                      │
│  - 性能指标监控（延迟、吞吐量、分类准确率）                                    │
│  - 异常日志记录（类别库自动持久化）                                           │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 4.2 核心模块设计

#### 模块1: 颜色聚类引擎 (ColorClusterEngine)
```python
class ColorClusterEngine:
    """
    核心分类引擎 - 实现Static Leader Algorithm
    """
    def __init__(self, 
                 threshold_base=10.0,
                 adaptive_threshold=True,
                 max_clusters=8):
        self.clusters = {}  # {category_id: LabColor基准}
        self.threshold_base = threshold_base
        self.adaptive_threshold = adaptive_threshold
        self.max_clusters = max_clusters
        self.history = {}  # {category_id: [ΔE历史值列表]}
        
    def classify(self, lab_vector: np.ndarray) -> dict:
        """分类主函数 - 返回分类结果"""
        if len(self.clusters) == 0:
            # 第一颗珠子，建立第一个类别
            new_id = self._create_new_cluster(lab_vector)
            return {
                'category_id': new_id,
                'is_new': True,
                'delta_e': 0.0,
                'confidence': 1.0
            }
        
        # 寻找最近邻
        min_dist, best_id = self._find_nearest(lab_vector)
        
        # 获取自适应阈值
        threshold = self._get_threshold(best_id) if self.adaptive_threshold else self.threshold_base
        
        if min_dist < threshold:
            # 匹配成功
            self.history[best_id].append(min_dist)
            return {
                'category_id': best_id,
                'is_new': False,
                'delta_e': min_dist,
                'confidence': 1.0 - (min_dist / threshold)
            }
        else:
            # 需要新建类别
            if len(self.clusters) >= self.max_clusters:
                return {
                    'category_id': None,  # 异常口
                    'is_new': False,
                    'delta_e': min_dist,
                    'confidence': 0.0
                }
            new_id = self._create_new_cluster(lab_vector)
            return {
                'category_id': new_id,
                'is_new': True,
                'delta_e': min_dist,
                'confidence': 1.0
            }
    
    def _get_threshold(self, category_id):
        """自适应阈值计算"""
        if category_id not in self.history or len(self.history[category_id]) < 10:
            return self.threshold_base
        
        history = self.history[category_id]
        mean_de = np.mean(history)
        std_de = np.std(history)
        # 3σ原则，但设置上下限
        adaptive = mean_de + 3 * std_de
        return np.clip(adaptive, self.threshold_base * 0.5, self.threshold_base * 1.5)
```

#### 模块2: 图像处理流水线 (ImageProcessingPipeline)
```python
class ImageProcessingPipeline:
    """
    完整的图像处理流程：白平衡 → ROI提取 → LAB转换 → 特征提取
    """
    def __init__(self, white_balance_gain=None):
        self.white_balance_gain = white_balance_gain  # RGB增益 [R_gain, G_gain, B_gain]
        self.roi_center_ratio = 0.4  # 中心采样区域比例（半径）
        
    def process(self, raw_image: np.ndarray) -> np.ndarray:
        """
        处理单张图像，返回LAB特征向量
        """
        # 1. 白平衡修正
        if self.white_balance_gain is not None:
            corrected = self._apply_white_balance(raw_image, self.white_balance_gain)
        else:
            corrected = raw_image
            
        # 2. 珠子分割（生成mask）
        mask = self._segment_bead(corrected)
        
        # 3. 提取中心区域mask
        center_mask = self._extract_center_region(mask)
        
        # 4. 转换为LAB
        lab_image = cv2.cvtColor(corrected, cv2.COLOR_BGR2LAB)
        
        # 5. 计算中心区域的LAB中值（抗高光）
        lab_vector = self._compute_lab_median(lab_image, center_mask)
        
        return lab_vector
    
    def _segment_bead(self, image):
        """珠子分割 - 使用深度学习方法或传统方法"""
        # 方案A: 使用深度学习（U-Net） - 精度高但需要训练数据
        # 方案B: 使用传统方法（当前MVP使用的方法）
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        h, s, v = cv2.split(hsv)
        
        # 背景扣除 + 高光过滤
        s_mask = cv2.threshold(s, 30, 255, cv2.THRESH_BINARY)[1]
        v_mask = cv2.threshold(v, 245, 255, cv2.THRESH_BINARY_INV)[1]
        mask = cv2.bitwise_and(s_mask, v_mask)
        
        # 形态学操作
        kernel = np.ones((5,5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        
        # 找到最大连通域（假设只有一颗珠子）
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            largest = max(contours, key=cv2.contourArea)
            mask_final = np.zeros_like(mask)
            cv2.fillPoly(mask_final, [largest], 255)
            return mask_final
        return mask
        
    def _extract_center_region(self, mask):
        """提取mask的中心区域（圆形，半径40%）"""
        # 计算mask的质心
        M = cv2.moments(mask)
        if M["m00"] == 0:
            return mask
        cx = int(M["m10"] / M["m00"])
        cy = int(M["m01"] / M["m00"])
        
        # 计算半径（取mask等效圆半径的40%）
        area = np.sum(mask > 0)
        radius = int(np.sqrt(area / np.pi) * 0.4)
        
        # 创建圆形mask
        center_mask = np.zeros_like(mask)
        cv2.circle(center_mask, (cx, cy), radius, 255, -1)
        
        # 与原始mask取交集
        return cv2.bitwise_and(mask, center_mask)
    
    def _compute_lab_median(self, lab_image, mask):
        """计算mask区域的LAB中值（而非均值，抗高光）"""
        masked_pixels = lab_image[mask > 0]
        if len(masked_pixels) == 0:
            return np.array([50, 0, 0])  # 默认中性灰
        return np.median(masked_pixels, axis=0)
```

#### 模块3: 白平衡校准 (WhiteBalanceCalibrator)
```python
class WhiteBalanceCalibrator:
    """
    白卡校准模块 - 计算RGB增益系数
    """
    def __init__(self):
        self.gain = None  # [R_gain, G_gain, B_gain]
        
    def calibrate(self, white_card_image: np.ndarray) -> np.ndarray:
        """
        拍摄白卡图像，计算增益系数
        - 假设标准白卡的LAB值应为 (100, 0, 0) 或接近
        """
        # 提取图像中心区域（避免边缘阴影）
        h, w = white_card_image.shape[:2]
        roi = white_card_image[h//4:3*h//4, w//4:3*w//4]
        
        # 计算RGB均值
        mean_bgr = np.mean(roi, axis=(0, 1))
        
        # 假设标准白应该是 (255, 255, 255)，计算增益
        # 或者使用灰度世界假设（Gray World）：R_mean = G_mean = B_mean
        target = np.mean(mean_bgr)  # 目标亮度（使用平均值）
        self.gain = target / (mean_bgr + 1e-6)  # 避免除零
        
        logging.info(f"White balance gain calculated: R={self.gain[2]:.3f}, G={self.gain[1]:.3f}, B={self.gain[0]:.3f}")
        return self.gain
    
    def apply(self, image: np.ndarray) -> np.ndarray:
        """应用白平衡增益"""
        if self.gain is None:
            raise ValueError("White balance not calibrated. Call calibrate() first.")
        
        corrected = image.astype(np.float32)
        corrected[:, :, 0] *= self.gain[0]  # B
        corrected[:, :, 1] *= self.gain[1]  # G
        corrected[:, :, 2] *= self.gain[2]  # R
        corrected = np.clip(corrected, 0, 255).astype(np.uint8)
        return corrected
```

---

## 五、关键技术决策对比表 (Decision Matrix)

| 技术点 | 当前方案 | 推荐方案 | 理由 |
|--------|---------|---------|------|
| **颜色空间** | HSV | **CIELAB** | 符合人眼感知，光照稳定性好 |
| **距离度量** | 无（硬编码阈值） | **ΔE2000**（或ΔE94） | 国际标准，精度高 |
| **聚类算法** | 无 | **Static Leader** | 符合"首样基准"业务需求 |
| **特征提取** | HSV均值 | **LAB中值 + 中心加权** | 抗高光，更稳定 |
| **架构模式** | 单线程串行 | **多级流水线异步** | 吞吐量提升2-4倍 |
| **硬件触发** | 未实现 | **硬触发 + 编码器位置补偿** | 精确时序控制 |
| **状态持久化** | 无 | **JSON/Pickle存储** | 重启不丢失类别 |
| **异常检测** | 仅面积检查 | **多维度拒识规则** | 降低误分率 |

---

## 六、实施路线图 (Implementation Roadmap)

### Phase 1: 核心算法重构（1-2周）
1. ✅ 实现CIELAB颜色空间转换
2. ✅ 实现ΔE2000/ΔE94距离计算
3. ✅ 实现Static Leader Algorithm聚类引擎
4. ✅ 实现白平衡校准模块
5. ✅ 实现中心加权LAB特征提取

### Phase 2: 架构升级（1周）
1. ✅ 重构为多级异步流水线架构
2. ✅ 实现线程安全的队列通信
3. ✅ 添加性能监控模块

### Phase 3: 硬件集成（1-2周）
1. ✅ 研读EI400H编程手册，确定通信协议
2. ✅ 实现EI400H驱动接口
3. ✅ 实现编码器位置补偿的精确触发
4. ✅ 实现多通道管理

### Phase 4: 工程优化（1周）
1. ✅ 添加状态持久化（类别数据库）
2. ✅ 添加可视化调试界面（可选）
3. ✅ 添加日志与异常处理
4. ✅ 编写单元测试

### Phase 5: 现场测试与调优（持续）
1. ✅ 白平衡校准流程验证
2. ✅ 阈值参数调优（不同颜色类别）
3. ✅ 时序精度验证（编码器补偿）
4. ✅ 长期稳定性测试

---

## 七、风险评估与缓解 (Risk Mitigation)

| 风险 | 影响 | 缓解措施 |
|------|------|---------|
| **EI400H通信协议不明确** | 高 | 提前研读PDF手册，联系厂商技术支持，准备备用方案（通用IO板卡） |
| **流水线架构复杂性** | 中 | 先实现单线程版本验证算法，再升级架构；使用成熟框架（如Celery） |
| **ΔE2000计算开销** | 中 | 使用Cython/Numba加速；或降级为ΔE94 |
| **多线程调试困难** | 中 | 完善的日志系统；使用线程安全的队列；避免共享状态 |
| **现场环境变化** | 高 | 强制定期校准；自动检测环境光变化并告警 |

---

## 八、总结与建议 (Conclusion)

### 8.1 核心结论
1. **当前MVP代码与设计方案差距巨大** - 必须重构
2. **架构升级可带来2-4倍性能提升** - 值得投入
3. **EI400H集成是关键缺失** - 需优先解决

### 8.2 优先级建议
1. **P0（立即）**: 
   - 实现CIELAB + Static Leader Algorithm（核心算法）
   - 实现白平衡校准（精度保证）
   
2. **P1（1周内）**: 
   - 研读EI400H手册，完成硬件集成
   - 架构升级为流水线模式
   
3. **P2（2周内）**: 
   - 状态持久化
   - 可视化界面
   - 性能监控

### 8.3 推倒重来的理由
当前`bead_classifier_mvp.py`代码：
- ❌ 使用HSV而非LAB
- ❌ 硬编码阈值无法动态发现
- ❌ 无聚类逻辑
- ❌ 无白平衡
- ❌ 单线程架构

**建议**: 保留`camera_sdk_demo.py`的相机集成思路，但核心算法部分需要**完全重写**。

---

**文档结束**

*注: 本文档基于对现有代码和报告的分析，EI400H分选卡的具体集成方案需根据实际PDF手册内容调整。*

