## 新样本 Lab 归类逻辑说明（基于现有聚类结果）

> 目标：给已经完成一次聚类后的系统，定义一套**可执行、可实现**的新图片自动归类规则，并解释其依据。

---

## 一、前置条件与数据基础

当前系统一次聚类完成后，后端会输出每个类别的统计信息（见 `ClusterInfo`）和整体统计（见 `ClusterResult`），其中关键字段包括：

- **类别级统计（ClusterInfo）**  
  - `lab_mean: [L_mean, a_mean, b_mean]`  
    - 每个类别在 Lab 空间中的**颜色中心（平均值）**  
  - `de2000_intra_mean`、`de2000_intra_max`  
    - 在文档 `类内误差说明.md` 中已说明：这是**类内 ΔE2000 成对距离**的平均值和最大值，衡量类别内部整体一致性

- **全局统计（ClusterResult）**
  - `inter_cluster_stats.mean / min / max / std`  
    - 各类别中心之间的 ΔE2000（类间距离）统计，用于评估**类别之间的分离程度**，不直接作为新样本归属阈值

因此，我们已经具备：

1. 每个类别在 Lab 空间的**代表点（lab_mean）**
2. 每个类别内部**颜色波动的典型范围**（`de2000_intra_*`）

这为后续新样本的自动归类提供了充分依据。

---

## 二、核心思想：最近中心 + 类内距离阈值

对于一张新图片，其 Lab 值记为：
\[
Lab_{new} = (L^*, a^*, b^*)
\]

我们对每个类别 \(k\) 有：
\[
Lab_{mean}^{(k)} = (L_{mean}^{(k)}, a_{mean}^{(k)}, b_{mean}^{(k)})
\]

### 1. 最近中心原则（基础分类规则）

对每个类别 \(k\) 计算：
\[
d_k = \Delta E_{2000}\big( Lab_{new}, Lab_{mean}^{(k)} \big)
\]

取最小值：
\[
d_{\min} = \min_k d_k,\quad k^* = \arg\min_k d_k
\]

**解释：**

- 这一步等价于“**找出在感知颜色上最接近的类别中心**”
- 与 K-Means、最近邻分类器（Nearest Centroid Classifier）的经典做法一致，是颜色空间中合理的第一步判断

### 2. 为什么不能只看“最近”就直接归类

如果**只看谁最近**而不管距离大小，必然会出现以下风险：

- 即使新样本与所有类别都不相似（颜色差异非常大），也仍然会被“硬分”到一个最近的类别中
- 在实际业务里，这种样本通常应当被认为是：
  - “异常样本”
  - “潜在新类别”
  - 或“需要人工确认”

因此，需要在“最近中心”的基础上，再加一层**“这个最近靠不靠谱”的判断**。

### 3. 使用类内 ΔE2000 作为可信度依据

参考 `docs/类内误差说明.md`，我们知道：

- `de2000_intra_mean` / `de2000_intra_max` 度量的是
  - 类别内部所有样本之间的 ΔE2000 分布
- **它们反映的是“这个类别内部原本有多分散”**

所以对于最近类别 \(k^*\)，我们希望：

> 新样本到该类中心的距离 \(d_{\min}\)，**不要显著大于这个类别内部原有样本之间的典型距离**。

这就引出下面的阈值策略。

---

## 三、推荐的实际归类规则（可直接实现）

设：

- 对类别 \(k\)：
  - `lab_mean[k]`
  - `de2000_intra_mean[k]`
  - `de2000_intra_max[k]`

### 步骤 1：计算到所有类别中心的 ΔE2000

对每个类别 \(k\)：

1. 取中心颜色：`lab_mean[k] = [L_mean, a_mean, b_mean]`
2. 计算距离：
   \[
   d_k = \Delta E_{2000}(Lab_{new}, lab\_mean^{(k)})
   \]

### 步骤 2：选择最近的类别候选

1. 找到最小距离：
   \[
   d_{\min} = \min_k d_k,\quad k^* = \arg\min_k d_k
   \]
2. 临时候选类别为 `k*`

### 步骤 3：为最近类别设置“可信度阈值”

针对最近类别 \(k^*\)，定义一个阈值 `threshold_k*`，推荐使用如下保守策略之一：

- **方案 A：基于类内最大距离**

  ```text
  threshold_k* = de2000_intra_max[k*] * 1.1
  ```

  含义：
  - 原来类别内部**最远的两张图片**之间的 ΔE2000 为 `de2000_intra_max`
  - 对新样本，允许它到类别中心的距离**稍微大一点点**（例如 10% 的放宽），超过这个值则认为“不太像这个类别”

- **方案 B：基于类内平均距离 + 安全边界**

  如果后续扩展到有 `de2000_intra_std[k]`，可以写成：

  ```text
  threshold_k* = de2000_intra_mean[k*] + α * de2000_intra_std[k*]
  ```

  - `α` 可取 2 或 3（类似“2σ / 3σ 原则”）
  - 代表：只接受“距离中心不超过绝大多数类内样本波动范围”的新样本

目前在已有数据下，**方案 A（用 `de2000_intra_max`）即可落地**。

### 步骤 4：做最终归属判定

1. **如果**

   ```text
   d_min <= threshold_k*
   ```

   - 则：
     - **认定：新样本属于类别 k\***  
       （它与该类别原有样本的距离还在合理范围内）

2. **否则（d_min > threshold_k\*）**

   - 则：
     - 标记为：**“未知类别 / 可疑样本 / 待人工确认”**  
     - 可以做的后续动作包括：
       - 单独放入“未归类”池
       - 累积到一定数量后重新跑一次聚类
       - 或提示人工检查，决定是否新增类别

---

## 四、为什么不用“类间平均 ΔE2000”当阈值

系统中还提供了：

- `inter_cluster_stats.mean / min / max / std`

这些指标度量的是**类别中心之间的 ΔE2000**，即：

\[
\Delta E_{2000}\big( Lab_{mean}^{(i)}, Lab_{mean}^{(j)} \big),\quad i \neq j
\]

**它反映的是：不同类别之间“隔得有多远”**，适用于：

- 评估整个聚类的分离度（类间是否明显区分、是否有重叠）
- 分析是否存在“非常接近的两类”（例如 `inter_cluster_stats.min` 很小）

但用它来做“新样本是否属于某类”的阈值有以下问题：

- “类间平均距离”通常**远大于类内波动**，如果直接用作阈值：
  - 很多与该类别其实“已经明显不同”的新样本，也可能 `d_min < inter_cluster_stats.mean`，从而被误归类
- 新样本的判断逻辑，**更应该对比“这个类别内部原来长成什么样”**，而不是“这个类别和其它类别平均相距多远”

因此，**更合理的依据是类内 ΔE2000（`de2000_intra_*`），而不是类间 ΔE2000。**

---

## 五、伪代码示例（Python 风格）

下面是一个可直接参考实现的伪代码，假设：

- `clusters` 为当前聚类结果中的类别字典（key 为类别 id，value 为统计信息）
- `delta_e2000(lab1, lab2)` 为已实现的 ΔE2000 计算函数

```python
from typing import Dict, Optional, Tuple

def classify_new_sample(
    lab_new: Tuple[float, float, float],
    clusters: Dict[int, dict],
    max_scale: float = 1.1,
) -> Optional[int]:
    """
    基于现有聚类结果，将新样本 (L, a, b) 归入某个类别。

    :param lab_new: 新样本的 Lab 值 (L*, a*, b*)
    :param clusters: 现有聚类结果中的类别统计信息
        需要包含:
            - "lab_mean": [L_mean, a_mean, b_mean]
            - "de2000_intra_max": float
    :param max_scale: 类内最大距离的放大系数，例如 1.1
    :return: 归属的类别 id；如果 None，表示“不确定 / 未归类”
    """
    L_new, a_new, b_new = lab_new

    best_cluster_id = None
    best_distance = float("inf")

    # 步骤 1：找最近类别
    for cid, info in clusters.items():
        Lm, am, bm = info["lab_mean"]
        d = delta_e2000((L_new, a_new, b_new), (Lm, am, bm))

        if d < best_distance:
            best_distance = d
            best_cluster_id = cid

    if best_cluster_id is None:
        return None

    # 步骤 2：对最近类别做可信度判断
    intra_max = clusters[best_cluster_id]["de2000_intra_max"]
    threshold = intra_max * max_scale

    if best_distance <= threshold:
        return best_cluster_id
    else:
        # 距离所有类别都偏远 → 标记为未归类
        return None
```

> 注意：上面代码的核心参数是 `max_scale`（如 1.05～1.2 可调）。  
> 在生产环境中，可以通过观察真实数据的分布与误判情况，对该参数进行校准。

---

## 六、结论与建议

- **结论 1：**  
  使用“新样本 Lab 与各类 `lab_mean` 的 ΔE2000 距离，选最近的类别”是合理的基础逻辑，与经典颜色聚类 / 最近中心分类方法一致。

- **结论 2：**  
  为了避免“离所有类别都很远但被硬塞到最近类别”的误判，需要基于**类内 ΔE2000 统计（`de2000_intra_*`）**增加距离阈值判断。

- **结论 3：**  
  “类间平均 ΔE2000”（`inter_cluster_stats.mean` 等）用于评估聚类整体质量与类别分离度，**不适合作为新样本归属的直接阈值**。

- **实践建议：**
  - 首选实现本文件第三部分的**“最近中心 + 类内最大距离放大系数”**规则；
  - 在实际运行一段时间后，根据误判/漏判情况，对 `max_scale` 或更复杂的阈值策略（如加入 `de2000_intra_mean`、标准差）做迭代优化。

